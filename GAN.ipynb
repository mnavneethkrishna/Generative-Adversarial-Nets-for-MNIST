{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnavneethkrishna/Generative-Adversarial-Nets-for-MNIST/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T5ISEmGmUwR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-cEv3VgvVHD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1e2isfjVPF7",
        "colab_type": "code",
        "outputId": "f292174a-9bc0-481c-d098-a965eb6b14f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#Import data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/temp/data/\",one_hot=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /temp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /temp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /temp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /temp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XQsSRbwcVfuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_steps = 100000\n",
        "batch_size = 128\n",
        "learning_rate = 0.0002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M42cR0ozVpkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_dim = 784\n",
        "gen_hidden_dim = 256\n",
        "disc_hidden_dim = 256\n",
        "noise_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eWvPtKKV71C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def glorot_init(shape):\n",
        "  return tf.random_normal(shape=shape, stddev=1./tf.sqrt(shape[0]/2.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pjt1Vvn9WMMP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    'gen_hidden1':tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n",
        "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n",
        "    'disc_hidden1': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n",
        "    'disc_out': tf.Variable(glorot_init([disc_hidden_dim, 1]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HcMbrQbKXEq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "biases = {\n",
        "    'gen_hidden1': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
        "    'gen_out': tf.Variable(tf.zeros([image_dim])),\n",
        "    'disc_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
        "    'disc_out': tf.Variable(tf.zeros([1]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RsPH1uY3Xs9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "def generator(x):\n",
        "  hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
        "  hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
        "  hidden_layer = tf.nn.relu(hidden_layer)\n",
        "  out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
        "  out_layer = tf.add(out_layer, biases['gen_out'])\n",
        "  out_layer = tf.nn.sigmoid(out_layer)\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJAKYuQmYWI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Discriminator\n",
        "def discriminator(x):\n",
        "  hidden_layer = tf.matmul(x, weights['disc_hidden1'])\n",
        "  hidden_layer = tf.add(hidden_layer, biases['disc_hidden1'])\n",
        "  hidden_layer = tf.nn.relu(hidden_layer)\n",
        "  out_layer = tf.matmul(hidden_layer, weights['disc_out'])\n",
        "  out_layer = tf.add(out_layer, biases['disc_out'])\n",
        "  out_layer = tf.nn.sigmoid(out_layer)\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKRrie-KY7Js",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build neural networks\n",
        "# Input to nns\n",
        "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
        "disc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeJ4tLJmZdTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build generator network\n",
        "gen_sample = generator(gen_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30tw9i40jHuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Buid discriminator\n",
        "disc_real = discriminator(disc_input)\n",
        "disc_fake = discriminator(gen_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aR_nfJ7qjoRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build loss\n",
        "gen_loss = - tf.reduce_mean(tf.log(disc_fake))\n",
        "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AhHn3762j8l1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build optimizers\n",
        "optimizer_gen = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "optimizer_disc = tf.train.AdamOptimizer(learning_rate = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-dYoZTWkQAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
        "           biases['disc_hidden1'], biases['disc_out']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCWBEsyTkgqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "disc_vars = [weights['disc_hidden1'], weights['disc_out'],\n",
        "            biases['disc_hidden1'], biases['disc_out']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_pfrUyy9kuin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training operations\n",
        "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
        "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DIqcEW0k_OT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DICjcP9jmJxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Z7h0qk2lDfK",
        "colab_type": "code",
        "outputId": "6e07fc7a-116b-4f18-b5ad-4e156d438755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for i in range(1, num_steps+1):\n",
        "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
        "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
        "    \n",
        "    # Train\n",
        "    feed_dict = {disc_input: batch_x, gen_input:z}\n",
        "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
        "                           feed_dict = feed_dict)\n",
        "    if i%1000 == 0 or i ==1:\n",
        "      print(\"Step %i: Generator loss: %f, Discriminator loss: %f\" %(i, gl, dl))\n",
        "    \n",
        "   # Generate images from noise\n",
        "  f, a = plt.subplots(4, 10, figsize=(10,4))\n",
        "  plt.grid(False)\n",
        "  plt.axis(\"off\")\n",
        "  for i in range(10):\n",
        "    z = np.random.uniform(-1.,1., size=[4, noise_dim])\n",
        "    g = sess.run([gen_sample], feed_dict= {gen_input:z})\n",
        "    g = np.reshape(g, newshape=(4, 28, 28, 1))\n",
        "      \n",
        "    g = -1 * (g-1)\n",
        "    for j in range(4):\n",
        "      img = np.reshape(np.repeat(g[j][:,:,np.newaxis], 3, axis=2), \n",
        "                        newshape=(28,28,3))\n",
        "      a[j][i].imshow(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1: Generator loss: 0.811930, Discriminator loss: 1.580781\n",
            "Step 1000: Generator loss: 3.496656, Discriminator loss: 0.105565\n",
            "Step 2000: Generator loss: 0.716802, Discriminator loss: 0.855015\n",
            "Step 3000: Generator loss: 2.354581, Discriminator loss: 0.138019\n",
            "Step 4000: Generator loss: 3.249256, Discriminator loss: 0.134883\n",
            "Step 5000: Generator loss: 3.526403, Discriminator loss: 0.122040\n",
            "Step 6000: Generator loss: 1.537553, Discriminator loss: 0.464054\n",
            "Step 7000: Generator loss: 1.923666, Discriminator loss: 0.284344\n",
            "Step 8000: Generator loss: 1.623930, Discriminator loss: 0.418051\n",
            "Step 9000: Generator loss: 1.987200, Discriminator loss: 0.320738\n",
            "Step 10000: Generator loss: 2.024975, Discriminator loss: 0.315969\n",
            "Step 11000: Generator loss: 1.876241, Discriminator loss: 0.404089\n",
            "Step 12000: Generator loss: 1.960771, Discriminator loss: 0.295165\n",
            "Step 13000: Generator loss: 2.054698, Discriminator loss: 0.414191\n",
            "Step 14000: Generator loss: 2.033779, Discriminator loss: 0.439397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9LzuCOqunHWB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}