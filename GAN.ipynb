{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "T5ISEmGmUwR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-cEv3VgvVHD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1e2isfjVPF7",
        "colab_type": "code",
        "outputId": "f292174a-9bc0-481c-d098-a965eb6b14f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#Import data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/temp/data/\",one_hot=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /temp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /temp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /temp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /temp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XQsSRbwcVfuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_steps = 100000\n",
        "batch_size = 128\n",
        "learning_rate = 0.0002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M42cR0ozVpkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_dim = 784\n",
        "gen_hidden_dim = 256\n",
        "disc_hidden_dim = 256\n",
        "noise_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eWvPtKKV71C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def glorot_init(shape):\n",
        "  return tf.random_normal(shape=shape, stddev=1./tf.sqrt(shape[0]/2.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pjt1Vvn9WMMP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    'gen_hidden1':tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n",
        "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n",
        "    'disc_hidden1': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n",
        "    'disc_out': tf.Variable(glorot_init([disc_hidden_dim, 1]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HcMbrQbKXEq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "biases = {\n",
        "    'gen_hidden1': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
        "    'gen_out': tf.Variable(tf.zeros([image_dim])),\n",
        "    'disc_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
        "    'disc_out': tf.Variable(tf.zeros([1]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RsPH1uY3Xs9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "def generator(x):\n",
        "  hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
        "  hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
        "  hidden_layer = tf.nn.relu(hidden_layer)\n",
        "  out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
        "  out_layer = tf.add(out_layer, biases['gen_out'])\n",
        "  out_layer = tf.nn.sigmoid(out_layer)\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJAKYuQmYWI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Discriminator\n",
        "def discriminator(x):\n",
        "  hidden_layer = tf.matmul(x, weights['disc_hidden1'])\n",
        "  hidden_layer = tf.add(hidden_layer, biases['disc_hidden1'])\n",
        "  hidden_layer = tf.nn.relu(hidden_layer)\n",
        "  out_layer = tf.matmul(hidden_layer, weights['disc_out'])\n",
        "  out_layer = tf.add(out_layer, biases['disc_out'])\n",
        "  out_layer = tf.nn.sigmoid(out_layer)\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKRrie-KY7Js",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build neural networks\n",
        "# Input to nns\n",
        "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
        "disc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeJ4tLJmZdTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build generator network\n",
        "gen_sample = generator(gen_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30tw9i40jHuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Buid discriminator\n",
        "disc_real = discriminator(disc_input)\n",
        "disc_fake = discriminator(gen_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aR_nfJ7qjoRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build loss\n",
        "gen_loss = - tf.reduce_mean(tf.log(disc_fake))\n",
        "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AhHn3762j8l1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build optimizers\n",
        "optimizer_gen = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "optimizer_disc = tf.train.AdamOptimizer(learning_rate = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-dYoZTWkQAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
        "           biases['disc_hidden1'], biases['disc_out']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCWBEsyTkgqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "disc_vars = [weights['disc_hidden1'], weights['disc_out'],\n",
        "            biases['disc_hidden1'], biases['disc_out']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_pfrUyy9kuin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training operations\n",
        "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
        "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DIqcEW0k_OT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DICjcP9jmJxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Z7h0qk2lDfK",
        "colab_type": "code",
        "outputId": "391d7e38-cfa6-4dcb-e749-dfab4aac77db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for i in range(1, num_steps+1):\n",
        "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
        "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
        "    \n",
        "    # Train\n",
        "    feed_dict = {disc_input: batch_x, gen_input:z}\n",
        "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
        "                           feed_dict = feed_dict)\n",
        "    if i%1000 == 0 or i ==1:\n",
        "      print(\"Step %i: Generator loss: %f, Discriminator loss: %f\" %(i, gl, dl))\n",
        "    \n",
        "   # Generate images from noise\n",
        "  f, a = plt.subplots(4, 10, figsize=(10,4))\n",
        "  plt.grid(False)\n",
        "  for i in range(10):\n",
        "    z = np.random.uniform(-1.,1., size=[4, noise_dim])\n",
        "    g = sess.run([gen_sample], feed_dict= {gen_input:z})\n",
        "    g = np.reshape(g, newshape=(4, 28, 28, 1))\n",
        "      \n",
        "    g = -1 * (g-1)\n",
        "    for j in range(4):\n",
        "      img = np.reshape(np.repeat(g[j][:,:,np.newaxis], 3, axis=2), \n",
        "                        newshape=(28,28,3))\n",
        "      a[j][i].imshow(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1: Generator loss: 0.474369, Discriminator loss: 1.600104\n",
            "Step 1000: Generator loss: 3.112077, Discriminator loss: 0.156244\n",
            "Step 2000: Generator loss: 3.170181, Discriminator loss: 0.118872\n",
            "Step 3000: Generator loss: 1.873193, Discriminator loss: 0.214554\n",
            "Step 4000: Generator loss: 2.292033, Discriminator loss: 0.180168\n",
            "Step 5000: Generator loss: 2.177052, Discriminator loss: 0.253006\n",
            "Step 6000: Generator loss: 1.732029, Discriminator loss: 0.342236\n",
            "Step 7000: Generator loss: 1.889333, Discriminator loss: 0.340520\n",
            "Step 8000: Generator loss: 1.792436, Discriminator loss: 0.356928\n",
            "Step 9000: Generator loss: 1.696798, Discriminator loss: 0.370294\n",
            "Step 10000: Generator loss: 1.832436, Discriminator loss: 0.400136\n",
            "Step 11000: Generator loss: 1.793250, Discriminator loss: 0.389374\n",
            "Step 12000: Generator loss: 1.903099, Discriminator loss: 0.433791\n",
            "Step 13000: Generator loss: 1.775177, Discriminator loss: 0.385722\n",
            "Step 14000: Generator loss: 1.818238, Discriminator loss: 0.413817\n",
            "Step 15000: Generator loss: 1.613629, Discriminator loss: 0.414589\n",
            "Step 16000: Generator loss: 1.807249, Discriminator loss: 0.431663\n",
            "Step 17000: Generator loss: 1.672243, Discriminator loss: 0.451580\n",
            "Step 18000: Generator loss: 1.685275, Discriminator loss: 0.424609\n",
            "Step 19000: Generator loss: 1.988619, Discriminator loss: 0.350748\n",
            "Step 20000: Generator loss: 1.635830, Discriminator loss: 0.441358\n",
            "Step 21000: Generator loss: 2.012660, Discriminator loss: 0.420701\n",
            "Step 22000: Generator loss: 1.820805, Discriminator loss: 0.450968\n",
            "Step 23000: Generator loss: 1.627764, Discriminator loss: 0.601339\n",
            "Step 24000: Generator loss: 1.674243, Discriminator loss: 0.396270\n",
            "Step 25000: Generator loss: 1.619562, Discriminator loss: 0.563266\n",
            "Step 26000: Generator loss: 1.419626, Discriminator loss: 0.594049\n",
            "Step 27000: Generator loss: 1.574068, Discriminator loss: 0.542070\n",
            "Step 28000: Generator loss: 1.602461, Discriminator loss: 0.550475\n",
            "Step 29000: Generator loss: 1.686614, Discriminator loss: 0.421736\n",
            "Step 30000: Generator loss: 1.706386, Discriminator loss: 0.534240\n",
            "Step 31000: Generator loss: 1.729272, Discriminator loss: 0.470136\n",
            "Step 32000: Generator loss: 1.771081, Discriminator loss: 0.452932\n",
            "Step 33000: Generator loss: 1.614232, Discriminator loss: 0.550335\n",
            "Step 34000: Generator loss: 1.799434, Discriminator loss: 0.620692\n",
            "Step 35000: Generator loss: 1.615769, Discriminator loss: 0.538608\n",
            "Step 36000: Generator loss: 1.534915, Discriminator loss: 0.708838\n",
            "Step 37000: Generator loss: 1.521846, Discriminator loss: 0.555827\n",
            "Step 38000: Generator loss: 1.461916, Discriminator loss: 0.587956\n",
            "Step 39000: Generator loss: 1.532443, Discriminator loss: 0.518272\n",
            "Step 40000: Generator loss: 1.438974, Discriminator loss: 0.548212\n",
            "Step 41000: Generator loss: 1.193195, Discriminator loss: 0.799444\n",
            "Step 42000: Generator loss: 1.377291, Discriminator loss: 0.679940\n",
            "Step 43000: Generator loss: 1.395506, Discriminator loss: 0.509926\n",
            "Step 44000: Generator loss: 1.593156, Discriminator loss: 0.524117\n",
            "Step 45000: Generator loss: 1.459522, Discriminator loss: 0.565181\n",
            "Step 46000: Generator loss: 1.406551, Discriminator loss: 0.554980\n",
            "Step 47000: Generator loss: 1.383807, Discriminator loss: 0.607647\n",
            "Step 48000: Generator loss: 1.287373, Discriminator loss: 0.616817\n",
            "Step 49000: Generator loss: 1.416684, Discriminator loss: 0.507682\n",
            "Step 50000: Generator loss: 1.600464, Discriminator loss: 0.554237\n",
            "Step 51000: Generator loss: 1.420062, Discriminator loss: 0.575306\n",
            "Step 52000: Generator loss: 1.262116, Discriminator loss: 0.611150\n",
            "Step 53000: Generator loss: 1.386299, Discriminator loss: 0.614626\n",
            "Step 54000: Generator loss: 1.280331, Discriminator loss: 0.657555\n",
            "Step 55000: Generator loss: 1.439587, Discriminator loss: 0.655079\n",
            "Step 56000: Generator loss: 1.380825, Discriminator loss: 0.588054\n",
            "Step 57000: Generator loss: 1.385442, Discriminator loss: 0.563976\n",
            "Step 58000: Generator loss: 1.446201, Discriminator loss: 0.559269\n",
            "Step 59000: Generator loss: 1.209930, Discriminator loss: 0.678213\n",
            "Step 60000: Generator loss: 1.295456, Discriminator loss: 0.624094\n",
            "Step 61000: Generator loss: 1.382240, Discriminator loss: 0.620032\n",
            "Step 62000: Generator loss: 1.285514, Discriminator loss: 0.627140\n",
            "Step 63000: Generator loss: 1.205942, Discriminator loss: 0.702229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9LzuCOqunHWB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}